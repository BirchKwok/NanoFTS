"""
NanoFTS æ•°æ®å¯¼å…¥æµ‹è¯•

æµ‹è¯•å„ç§æ•°æ®æºå¯¼å…¥åŠŸèƒ½ï¼š
- from_pandas() - ä» pandas DataFrame å¯¼å…¥
- from_polars() - ä» Polars DataFrame å¯¼å…¥
- from_arrow() - ä» PyArrow Table å¯¼å…¥
- from_parquet() - ä» Parquet æ–‡ä»¶å¯¼å…¥
- from_csv() - ä» CSV æ–‡ä»¶å¯¼å…¥
- from_json() - ä» JSON æ–‡ä»¶å¯¼å…¥
- from_dict() - ä»å­—å…¸åˆ—è¡¨å¯¼å…¥
"""

import pytest
import os
from nanofts import create_engine


@pytest.fixture
def tmp_index_file(tmp_path):
    """åˆ›å»ºä¸´æ—¶ç´¢å¼•æ–‡ä»¶è·¯å¾„"""
    return str(tmp_path / "test_import.nfts")


@pytest.fixture
def engine(tmp_index_file):
    """åˆ›å»ºæµ‹è¯•å¼•æ“"""
    return create_engine(tmp_index_file, drop_if_exists=True)


@pytest.fixture
def sample_data():
    """ç¤ºä¾‹æ•°æ®"""
    return [
        {'id': 1, 'title': 'Hello World', 'content': 'This is a test document'},
        {'id': 2, 'title': 'å…¨æ–‡æœç´¢', 'content': 'æ”¯æŒå¤šè¯­è¨€æœç´¢'},
        {'id': 3, 'title': 'Python Document', 'content': 'Another test content'},
        {'id': 4, 'title': 'Mixed æ··åˆ', 'content': 'Both English and ä¸­æ–‡'},
        {'id': 5, 'title': 'Search Engine', 'content': 'Fast and efficient'},
    ]


# ==================== from_pandas æµ‹è¯• ====================

class TestFromPandas:
    """æµ‹è¯• from_pandas æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame(sample_data)
        count = engine.from_pandas(df, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
        assert engine.search("å…¨æ–‡").total_hits == 1
        assert engine.search("test").total_hits == 2
    
    def test_custom_text_columns(self, engine):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['A', 'B', 'C'],
            'content': ['Content 1', 'Content 2', 'Content 3'],
            'metadata': ['Meta 1', 'Meta 2', 'Meta 3']  # ä¸ç´¢å¼•æ­¤åˆ—
        })
        
        count = engine.from_pandas(df, id_column='id', text_columns=['title', 'content'])
        
        assert count == 3
        
        # title å’Œ content åº”è¯¥å¯æœç´¢
        assert engine.search("content").total_hits == 3
        
        # metadata ä¸åº”è¯¥è¢«ç´¢å¼•
        assert engine.search("meta").total_hits == 0
    
    def test_different_id_column(self, engine):
        """æµ‹è¯•ä¸åŒçš„ ID åˆ—å"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'doc_id': [100, 200, 300],
            'text': ['Document A', 'Document B', 'Document C']
        })
        
        count = engine.from_pandas(df, id_column='doc_id')
        
        assert count == 3
        
        result = engine.search("document")
        assert result.total_hits == 3
        assert 100 in result.to_list()
        assert 200 in result.to_list()
        assert 300 in result.to_list()
    
    def test_empty_dataframe(self, engine):
        """æµ‹è¯•ç©º DataFrame"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame(columns=['id', 'title', 'content'])
        count = engine.from_pandas(df, id_column='id')
        
        assert count == 0
    
    def test_chinese_content(self, engine):
        """æµ‹è¯•ä¸­æ–‡å†…å®¹"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['åŒ—äº¬å¸‚', 'ä¸Šæµ·å¸‚', 'å¹¿å·å¸‚'],
            'content': ['é¦–éƒ½åŸå¸‚', 'ç»æµä¸­å¿ƒ', 'å—æ–¹é—¨æˆ·']
        })
        
        count = engine.from_pandas(df, id_column='id')
        
        assert count == 3
        
        assert engine.search("åŒ—äº¬").total_hits == 1
        assert engine.search("åŸå¸‚").total_hits == 1
    
    def test_numeric_content(self, engine):
        """æµ‹è¯•æ•°å€¼å†…å®¹ï¼ˆè‡ªåŠ¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼‰"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['Product A', 'Product B', 'Product C'],
            'price': [100, 200, 300]
        })
        
        count = engine.from_pandas(df, id_column='id')
        
        assert count == 3
        
        # æ•°å€¼è¢«è½¬æ¢ä¸ºå­—ç¬¦ä¸²åå¯æœç´¢
        assert engine.search("100").total_hits == 1
    
    def test_null_values(self, engine):
        """æµ‹è¯•ç©ºå€¼å¤„ç†"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['Has Title', None, 'Another Title'],
            'content': ['Content 1', 'Content 2', None]
        })
        
        count = engine.from_pandas(df, id_column='id')
        
        assert count == 3
        
        # åº”è¯¥èƒ½æœç´¢åˆ°éç©ºå†…å®¹
        assert engine.search("title").total_hits == 2


# ==================== from_polars æµ‹è¯• ====================

class TestFromPolars:
    """æµ‹è¯• from_polars æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        pl = pytest.importorskip("polars")
        
        df = pl.DataFrame(sample_data)
        count = engine.from_polars(df, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
        assert engine.search("å…¨æ–‡").total_hits == 1
    
    def test_custom_text_columns(self, engine):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        pl = pytest.importorskip("polars")
        
        df = pl.DataFrame({
            'id': [1, 2, 3],
            'title': ['Title 1', 'Title 2', 'Title 3'],
            'content': ['Content 1', 'Content 2', 'Content 3'],
            'private': ['Private 1', 'Private 2', 'Private 3']
        })
        
        count = engine.from_polars(df, id_column='id', text_columns=['title', 'content'])
        
        assert count == 3
        
        assert engine.search("title").total_hits == 3
        assert engine.search("private").total_hits == 0
    
    def test_different_id_column(self, engine):
        """æµ‹è¯•ä¸åŒçš„ ID åˆ—å"""
        pl = pytest.importorskip("polars")
        
        df = pl.DataFrame({
            'doc_id': [10, 20, 30],
            'text': ['Polars Doc A', 'Polars Doc B', 'Polars Doc C']
        })
        
        count = engine.from_polars(df, id_column='doc_id')
        
        assert count == 3
        
        result = engine.search("polars")
        assert result.total_hits == 3
        assert 10 in result.to_list()
    
    def test_large_dataframe(self, engine):
        """æµ‹è¯•å¤§æ•°æ®é‡"""
        pl = pytest.importorskip("polars")
        
        df = pl.DataFrame({
            'id': list(range(1000)),
            'content': [f'Document content number {i}' for i in range(1000)]
        })
        
        count = engine.from_polars(df, id_column='id')
        
        assert count == 1000
        
        result = engine.search("document")
        assert result.total_hits == 1000


# ==================== from_arrow æµ‹è¯• ====================

class TestFromArrow:
    """æµ‹è¯• from_arrow æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        pa = pytest.importorskip("pyarrow")
        
        table = pa.Table.from_pydict({
            'id': [d['id'] for d in sample_data],
            'title': [d['title'] for d in sample_data],
            'content': [d['content'] for d in sample_data]
        })
        
        count = engine.from_arrow(table, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
    
    def test_custom_text_columns(self, engine):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        pa = pytest.importorskip("pyarrow")
        
        table = pa.Table.from_pydict({
            'id': [1, 2, 3],
            'indexable': ['Index A', 'Index B', 'Index C'],
            'skip': ['Skip A', 'Skip B', 'Skip C']
        })
        
        count = engine.from_arrow(table, id_column='id', text_columns=['indexable'])
        
        assert count == 3
        
        assert engine.search("index").total_hits == 3
        assert engine.search("skip").total_hits == 0
    
    def test_from_pandas_conversion(self, engine):
        """æµ‹è¯•ä» pandas è½¬æ¢çš„ Arrow Table"""
        pd = pytest.importorskip("pandas")
        pa = pytest.importorskip("pyarrow")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['Arrow A', 'Arrow B', 'Arrow C']
        })
        
        table = pa.Table.from_pandas(df)
        count = engine.from_arrow(table, id_column='id')
        
        assert count == 3
        
        result = engine.search("arrow")
        assert result.total_hits == 3


# ==================== from_parquet æµ‹è¯• ====================

class TestFromParquet:
    """æµ‹è¯• from_parquet æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data, tmp_path):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        pa = pytest.importorskip("pyarrow")
        pq = pytest.importorskip("pyarrow.parquet")
        
        # åˆ›å»º Parquet æ–‡ä»¶
        table = pa.Table.from_pydict({
            'id': [d['id'] for d in sample_data],
            'title': [d['title'] for d in sample_data],
            'content': [d['content'] for d in sample_data]
        })
        
        parquet_path = tmp_path / "test.parquet"
        pq.write_table(table, parquet_path)
        
        # å¯¼å…¥
        count = engine.from_parquet(parquet_path, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
        assert engine.search("å…¨æ–‡").total_hits == 1
    
    def test_custom_text_columns(self, engine, tmp_path):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        pa = pytest.importorskip("pyarrow")
        pq = pytest.importorskip("pyarrow.parquet")
        
        table = pa.Table.from_pydict({
            'id': [1, 2, 3],
            'searchable': ['Search A', 'Search B', 'Search C'],
            'hidden': ['Hidden A', 'Hidden B', 'Hidden C']
        })
        
        parquet_path = tmp_path / "test.parquet"
        pq.write_table(table, parquet_path)
        
        count = engine.from_parquet(parquet_path, id_column='id', text_columns=['searchable'])
        
        assert count == 3
        
        assert engine.search("search").total_hits == 3
        assert engine.search("hidden").total_hits == 0
    
    def test_string_path(self, engine, sample_data, tmp_path):
        """æµ‹è¯•å­—ç¬¦ä¸²è·¯å¾„"""
        pa = pytest.importorskip("pyarrow")
        pq = pytest.importorskip("pyarrow.parquet")
        
        table = pa.Table.from_pydict({
            'id': [d['id'] for d in sample_data],
            'title': [d['title'] for d in sample_data]
        })
        
        parquet_path = str(tmp_path / "test_string_path.parquet")
        pq.write_table(table, parquet_path)
        
        count = engine.from_parquet(parquet_path, id_column='id')
        
        assert count == 5


# ==================== from_csv æµ‹è¯• ====================

class TestFromCSV:
    """æµ‹è¯• from_csv æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data, tmp_path):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        pd = pytest.importorskip("pandas")
        
        # åˆ›å»º CSV æ–‡ä»¶
        df = pd.DataFrame(sample_data)
        csv_path = tmp_path / "test.csv"
        df.to_csv(csv_path, index=False)
        
        # å¯¼å…¥
        count = engine.from_csv(csv_path, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
        assert engine.search("å…¨æ–‡").total_hits == 1
    
    def test_custom_text_columns(self, engine, tmp_path):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['CSV Title 1', 'CSV Title 2', 'CSV Title 3'],
            'ignore': ['Ignore 1', 'Ignore 2', 'Ignore 3']
        })
        
        csv_path = tmp_path / "test.csv"
        df.to_csv(csv_path, index=False)
        
        count = engine.from_csv(csv_path, id_column='id', text_columns=['title'])
        
        assert count == 3
        
        assert engine.search("csv").total_hits == 3
        assert engine.search("ignore").total_hits == 0
    
    def test_csv_options(self, engine, tmp_path):
        """æµ‹è¯• CSV é€‰é¡¹"""
        pd = pytest.importorskip("pandas")
        
        # åˆ›å»ºä½¿ç”¨åˆ†å·åˆ†éš”çš„ CSV
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['Semicolon 1', 'Semicolon 2', 'Semicolon 3']
        })
        
        csv_path = tmp_path / "test_semicolon.csv"
        df.to_csv(csv_path, index=False, sep=';')
        
        # ä½¿ç”¨ sep é€‰é¡¹å¯¼å…¥
        count = engine.from_csv(csv_path, id_column='id', sep=';')
        
        assert count == 3
        
        result = engine.search("semicolon")
        assert result.total_hits == 3
    
    def test_encoding(self, engine, tmp_path):
        """æµ‹è¯•ç¼–ç é€‰é¡¹"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['ä¸­æ–‡æ ‡é¢˜1', 'ä¸­æ–‡æ ‡é¢˜2', 'ä¸­æ–‡æ ‡é¢˜3']
        })
        
        csv_path = tmp_path / "test_utf8.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8')
        
        count = engine.from_csv(csv_path, id_column='id', encoding='utf-8')
        
        assert count == 3
        
        result = engine.search("ä¸­æ–‡")
        assert result.total_hits == 3


# ==================== from_json æµ‹è¯• ====================

class TestFromJSON:
    """æµ‹è¯• from_json æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data, tmp_path):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        pd = pytest.importorskip("pandas")
        
        # åˆ›å»º JSON æ–‡ä»¶
        df = pd.DataFrame(sample_data)
        json_path = tmp_path / "test.json"
        df.to_json(json_path, orient='records')
        
        # å¯¼å…¥
        count = engine.from_json(json_path, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
    
    def test_json_lines(self, engine, tmp_path):
        """æµ‹è¯• JSON Lines æ ¼å¼"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'title': ['JSON Line 1', 'JSON Line 2', 'JSON Line 3']
        })
        
        jsonl_path = tmp_path / "test.jsonl"
        df.to_json(jsonl_path, orient='records', lines=True)
        
        count = engine.from_json(jsonl_path, id_column='id', lines=True)
        
        assert count == 3
        
        result = engine.search("json")
        assert result.total_hits == 3
    
    def test_custom_text_columns(self, engine, tmp_path):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        pd = pytest.importorskip("pandas")
        
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'include': ['Include A', 'Include B', 'Include C'],
            'exclude': ['Exclude A', 'Exclude B', 'Exclude C']
        })
        
        json_path = tmp_path / "test.json"
        df.to_json(json_path, orient='records')
        
        count = engine.from_json(json_path, id_column='id', text_columns=['include'])
        
        assert count == 3
        
        assert engine.search("include").total_hits == 3
        assert engine.search("exclude").total_hits == 0


# ==================== from_dict æµ‹è¯• ====================

class TestFromDict:
    """æµ‹è¯• from_dict æ–¹æ³•"""
    
    def test_basic_import(self, engine, sample_data):
        """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
        count = engine.from_dict(sample_data, id_column='id')
        
        assert count == 5
        
        # éªŒè¯æ•°æ®å¯æœç´¢
        assert engine.search("hello").total_hits == 1
        assert engine.search("å…¨æ–‡").total_hits == 1
    
    def test_custom_text_columns(self, engine):
        """æµ‹è¯•æŒ‡å®šæ–‡æœ¬åˆ—"""
        data = [
            {'id': 1, 'title': 'Dict Title 1', 'secret': 'Secret 1'},
            {'id': 2, 'title': 'Dict Title 2', 'secret': 'Secret 2'},
            {'id': 3, 'title': 'Dict Title 3', 'secret': 'Secret 3'},
        ]
        
        count = engine.from_dict(data, id_column='id', text_columns=['title'])
        
        assert count == 3
        
        assert engine.search("dict").total_hits == 3
        assert engine.search("secret").total_hits == 0
    
    def test_empty_list(self, engine):
        """æµ‹è¯•ç©ºåˆ—è¡¨"""
        count = engine.from_dict([], id_column='id')
        
        assert count == 0
    
    def test_different_id_column(self, engine):
        """æµ‹è¯•ä¸åŒçš„ ID åˆ—å"""
        data = [
            {'doc_id': 100, 'text': 'Dict Doc A'},
            {'doc_id': 200, 'text': 'Dict Doc B'},
            {'doc_id': 300, 'text': 'Dict Doc C'},
        ]
        
        count = engine.from_dict(data, id_column='doc_id')
        
        assert count == 3
        
        result = engine.search("dict")
        assert result.total_hits == 3
        assert 100 in result.to_list()
    
    def test_missing_fields(self, engine):
        """æµ‹è¯•ç¼ºå¤±å­—æ®µ"""
        data = [
            {'id': 1, 'title': 'Has All Fields', 'content': 'Content 1'},
            {'id': 2, 'title': 'Missing Content'},  # ç¼ºå°‘ content
            {'id': 3, 'content': 'Missing Title'},  # ç¼ºå°‘ title
        ]
        
        count = engine.from_dict(data, id_column='id')
        
        assert count == 3
        
        # åº”è¯¥èƒ½æœç´¢åˆ°æœ‰å€¼çš„å­—æ®µ
        assert engine.search("missing").total_hits == 2


# ==================== ç»¼åˆæµ‹è¯• ====================

class TestMixedImport:
    """ç»¼åˆå¯¼å…¥æµ‹è¯•"""
    
    def test_multiple_imports(self, engine):
        """æµ‹è¯•å¤šæ¬¡å¯¼å…¥"""
        # ç¬¬ä¸€æ¬¡å¯¼å…¥
        data1 = [
            {'id': 1, 'content': 'First batch document 1'},
            {'id': 2, 'content': 'First batch document 2'},
        ]
        count1 = engine.from_dict(data1, id_column='id')
        assert count1 == 2
        
        # ç¬¬äºŒæ¬¡å¯¼å…¥
        data2 = [
            {'id': 3, 'content': 'Second batch document 3'},
            {'id': 4, 'content': 'Second batch document 4'},
        ]
        count2 = engine.from_dict(data2, id_column='id')
        assert count2 == 2
        
        # éªŒè¯ä¸¤æ‰¹æ•°æ®éƒ½å¯æœç´¢
        result = engine.search("batch")
        assert result.total_hits == 4
        
        result = engine.search("first")
        assert result.total_hits == 2
        
        result = engine.search("second")
        assert result.total_hits == 2
    
    def test_import_and_search_workflow(self, engine):
        """æµ‹è¯•å¯¼å…¥å’Œæœç´¢å·¥ä½œæµ"""
        # å¯¼å…¥æ•°æ®
        data = [
            {'id': 1, 'title': 'Machine Learning', 'content': 'Deep learning algorithms'},
            {'id': 2, 'title': 'Natural Language', 'content': 'Text processing NLP'},
            {'id': 3, 'title': 'Computer Vision', 'content': 'Image recognition CNN'},
            {'id': 4, 'title': 'Reinforcement Learning', 'content': 'Agent policy optimization'},
        ]
        
        engine.from_dict(data, id_column='id')
        
        # æµ‹è¯•å„ç§æœç´¢
        assert engine.search("learning").total_hits == 2
        assert engine.search("machine").total_hits == 1
        
        # æµ‹è¯• AND æœç´¢
        result = engine.search_and(["learning", "machine"])
        assert result.total_hits == 1
        assert 1 in result.to_list()
        
        # æµ‹è¯• OR æœç´¢
        result = engine.search_or(["machine", "computer"])
        assert result.total_hits == 2
    
    def test_import_persistence(self, tmp_path):
        """æµ‹è¯•å¯¼å…¥åæŒä¹…åŒ–"""
        index_file = str(tmp_path / "persist_test.nfts")
        
        # åˆ›å»ºå¼•æ“å¹¶å¯¼å…¥
        engine1 = create_engine(index_file, drop_if_exists=True)
        data = [
            {'id': 1, 'content': 'Persistent data 1'},
            {'id': 2, 'content': 'Persistent data 2'},
        ]
        engine1.from_dict(data, id_column='id')
        del engine1
        
        # é‡æ–°æ‰“å¼€å¹¶éªŒè¯
        engine2 = create_engine(index_file)
        result = engine2.search("persistent")
        
        assert result.total_hits == 2
        assert 1 in result.to_list()
        assert 2 in result.to_list()


# ==================== è¾¹ç¼˜æƒ…å†µæµ‹è¯• ====================

class TestEdgeCases:
    """è¾¹ç¼˜æƒ…å†µæµ‹è¯•"""
    
    def test_very_long_content(self, engine):
        """æµ‹è¯•è¶…é•¿å†…å®¹"""
        data = [
            {'id': 1, 'content': 'word ' * 10000},  # 50000 å­—ç¬¦
        ]
        
        count = engine.from_dict(data, id_column='id')
        
        assert count == 1
        
        result = engine.search("word")
        assert 1 in result.to_list()
    
    def test_special_characters(self, engine):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦"""
        data = [
            {'id': 1, 'content': 'Special @#$% characters!'},
            {'id': 2, 'content': 'Email test@example.com'},
            {'id': 3, 'content': 'URL https://example.com'},
        ]
        
        count = engine.from_dict(data, id_column='id')
        
        assert count == 3
        
        assert engine.search("special").total_hits == 1
        assert engine.search("email").total_hits == 1
    
    def test_unicode_content(self, engine):
        """æµ‹è¯• Unicode å†…å®¹"""
        data = [
            {'id': 1, 'content': 'æ—¥æœ¬èªãƒ†ã‚¹ãƒˆ'},
            {'id': 2, 'content': 'í•œêµ­ì–´ í…ŒìŠ¤íŠ¸'},
            {'id': 3, 'content': 'Emoji ğŸ‰ğŸŠ'},
        ]
        
        count = engine.from_dict(data, id_column='id')
        
        assert count == 3
    
    def test_large_id_values(self, engine):
        """æµ‹è¯•å¤§ ID å€¼"""
        data = [
            {'id': 1000000, 'content': 'Large ID 1'},
            {'id': 2000000, 'content': 'Large ID 2'},
            {'id': 2147483647, 'content': 'Max int ID'},  # æœ€å¤§ 32 ä½æ•´æ•°
        ]
        
        count = engine.from_dict(data, id_column='id')
        
        assert count == 3
        
        result = engine.search("large")
        assert 1000000 in result.to_list()
        assert 2000000 in result.to_list()


if __name__ == "__main__":
    pytest.main([__file__, "-v"])


