"""
NanoFTS è¾¹ç¼˜æƒ…å†µæµ‹è¯•

æµ‹è¯•å„ç§è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸æƒ…å†µï¼š
- ç©ºæŸ¥è¯¢/ç©ºæ–‡æ¡£
- è¶…é•¿æ–‡æœ¬
- ç‰¹æ®Šå­—ç¬¦
- æžå€¼ doc_id
- é‡å¤æ“ä½œ
"""

import pytest
import os
import tempfile
from nanofts import create_engine, UnifiedEngine


@pytest.fixture
def tmp_index_file(tmp_path):
    """åˆ›å»ºä¸´æ—¶ç´¢å¼•æ–‡ä»¶è·¯å¾„"""
    return str(tmp_path / "test_index.nfts")


@pytest.fixture
def engine(tmp_index_file):
    """åˆ›å»ºæµ‹è¯•å¼•æ“Ž"""
    return create_engine(tmp_index_file, drop_if_exists=True, track_doc_terms=True)


@pytest.fixture
def memory_engine():
    """åˆ›å»ºå†…å­˜æ¨¡å¼å¼•æ“Ž"""
    return create_engine("")


class TestEmptyOperations:
    """ç©ºæ“ä½œæµ‹è¯•"""
    
    def test_search_empty_index(self, engine):
        """æµ‹è¯•åœ¨ç©ºç´¢å¼•ä¸Šæœç´¢"""
        result = engine.search("any query")
        assert len(result) == 0
        assert result.is_empty()
        assert result.total_hits == 0
    
    def test_search_empty_query(self, engine):
        """æµ‹è¯•ç©ºæŸ¥è¯¢å­—ç¬¦ä¸²"""
        # æ·»åŠ ä¸€äº›æ•°æ®
        engine.add_document(1, {"title": "Hello World"})
        engine.flush()
        
        result = engine.search("")
        assert len(result) == 0
    
    def test_search_whitespace_only_query(self, engine):
        """æµ‹è¯•ä»…åŒ…å«ç©ºç™½å­—ç¬¦çš„æŸ¥è¯¢"""
        engine.add_document(1, {"title": "Hello World"})
        engine.flush()
        
        result = engine.search("   ")
        assert len(result) == 0
        
        result = engine.search("\t\n")
        assert len(result) == 0
    
    def test_add_empty_document(self, engine):
        """æµ‹è¯•æ·»åŠ ç©ºæ–‡æ¡£"""
        engine.add_document(1, {})
        engine.flush()
        
        # ç©ºæ–‡æ¡£ä¸åº”è¯¥å½±å“æœç´¢
        result = engine.search("anything")
        assert len(result) == 0
    
    def test_add_document_with_empty_fields(self, engine):
        """æµ‹è¯•æ·»åŠ å­—æ®µä¸ºç©ºçš„æ–‡æ¡£"""
        engine.add_document(1, {"title": "", "content": ""})
        engine.flush()
        
        result = engine.search("anything")
        assert len(result) == 0
    
    def test_remove_nonexistent_document(self, engine):
        """æµ‹è¯•åˆ é™¤ä¸å­˜åœ¨çš„æ–‡æ¡£"""
        # ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        engine.remove_document(999)
        engine.flush()
        
        # å¼•æ“Žåº”è¯¥æ­£å¸¸å·¥ä½œ
        result = engine.search("test")
        assert len(result) == 0


class TestSpecialCharacters:
    """ç‰¹æ®Šå­—ç¬¦æµ‹è¯•"""
    
    def test_search_with_punctuation(self, engine):
        """æµ‹è¯•åŒ…å«æ ‡ç‚¹ç¬¦å·çš„æœç´¢"""
        engine.add_document(1, {"content": "Hello, World! How are you?"})
        engine.flush()
        
        result = engine.search("hello")
        assert 1 in result.to_list()
        
        result = engine.search("world")
        assert 1 in result.to_list()
    
    def test_search_with_unicode(self, engine):
        """æµ‹è¯• Unicode å­—ç¬¦"""
        engine.add_document(1, {"content": "ä½ å¥½ä¸–ç•Œ ðŸŽ‰ Ã©moji"})
        engine.flush()
        
        result = engine.search("ä½ å¥½")
        assert 1 in result.to_list()
    
    def test_search_with_numbers(self, engine):
        """æµ‹è¯•æ•°å­—å†…å®¹"""
        engine.add_document(1, {"content": "Version 2.0.1 released"})
        engine.add_document(2, {"content": "12345 numbers only"})
        engine.flush()
        
        result = engine.search("12345")
        assert 2 in result.to_list()
    
    def test_search_with_special_regex_chars(self, engine):
        """æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼ç‰¹æ®Šå­—ç¬¦"""
        engine.add_document(1, {"content": "test.*regex+pattern[a-z]"})
        engine.flush()
        
        # è¿™äº›ç‰¹æ®Šå­—ç¬¦åº”è¯¥è¢«å½“ä½œæ™®é€šå­—ç¬¦å¤„ç†
        result = engine.search("test")
        assert 1 in result.to_list()
    
    def test_mixed_language_search(self, engine):
        """æµ‹è¯•ä¸­è‹±æ–‡æ··åˆæœç´¢"""
        engine.add_document(1, {"content": "Helloä½ å¥½Worldä¸–ç•Œ"})
        engine.flush()
        
        result = engine.search("hello")
        assert 1 in result.to_list()
        
        result = engine.search("ä½ å¥½")
        assert 1 in result.to_list()
        
        result = engine.search("hello ä½ å¥½")
        assert 1 in result.to_list()


class TestExtremeValues:
    """æžå€¼æµ‹è¯•"""
    
    def test_very_long_text(self, engine):
        """æµ‹è¯•è¶…é•¿æ–‡æœ¬"""
        # åˆ›å»ºä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬
        long_text = "word " * 10000  # 50000 å­—ç¬¦
        engine.add_document(1, {"content": long_text})
        engine.flush()
        
        result = engine.search("word")
        assert 1 in result.to_list()
    
    def test_very_long_term(self, engine):
        """æµ‹è¯•è¶…é•¿å•è¯"""
        long_word = "a" * 1000
        engine.add_document(1, {"content": long_word})
        engine.flush()
        
        result = engine.search(long_word)
        # å¯èƒ½å› ä¸º min_term_length é™åˆ¶è€Œæœ‰ç»“æžœæˆ–æ²¡æœ‰ç»“æžœ
        # ä¸»è¦ç¡®ä¿ä¸ä¼šå´©æºƒ
    
    def test_large_doc_id(self, engine):
        """æµ‹è¯•å¤§ doc_id"""
        large_id = 2**31 - 1  # æœ€å¤§ 32 ä½æœ‰ç¬¦å·æ•´æ•°
        engine.add_document(large_id, {"content": "test content"})
        engine.flush()
        
        result = engine.search("test")
        assert large_id in result.to_list()
    
    def test_zero_doc_id(self, engine):
        """æµ‹è¯• doc_id ä¸º 0"""
        engine.add_document(0, {"content": "zero id document"})
        engine.flush()
        
        result = engine.search("zero")
        assert 0 in result.to_list()
    
    def test_many_documents(self, engine):
        """æµ‹è¯•å¤§é‡æ–‡æ¡£"""
        # æ·»åŠ  1000 ä¸ªæ–‡æ¡£
        docs = [(i, {"content": f"document number {i}"}) for i in range(1000)]
        engine.add_documents(docs)
        engine.flush()
        
        result = engine.search("document")
        assert result.total_hits == 1000
    
    def test_many_terms_per_document(self, engine):
        """æµ‹è¯•å•ä¸ªæ–‡æ¡£åŒ…å«å¤§é‡è¯æ¡"""
        # åˆ›å»ºåŒ…å« 1000 ä¸ªä¸åŒè¯çš„æ–‡æ¡£
        words = [f"word{i}" for i in range(1000)]
        content = " ".join(words)
        engine.add_document(1, {"content": content})
        engine.flush()
        
        # æœç´¢å…¶ä¸­ä¸€ä¸ªè¯
        result = engine.search("word500")
        assert 1 in result.to_list()


class TestDuplicateOperations:
    """é‡å¤æ“ä½œæµ‹è¯•"""
    
    def test_add_same_document_twice(self, engine):
        """æµ‹è¯•æ·»åŠ ç›¸åŒæ–‡æ¡£ä¸¤æ¬¡"""
        engine.add_document(1, {"content": "first content"})
        engine.add_document(1, {"content": "second content"})
        engine.flush()
        
        # åº”è¯¥ä¸¤ä¸ªå†…å®¹éƒ½èƒ½æœç´¢åˆ°ï¼ˆæˆ–è€…åŽè€…è¦†ç›–å‰è€…ï¼Œå–å†³äºŽå®žçŽ°ï¼‰
        result1 = engine.search("first")
        result2 = engine.search("second")
        
        # è‡³å°‘ç¬¬äºŒæ¬¡æ·»åŠ åº”è¯¥ç”Ÿæ•ˆ
        assert 1 in result2.to_list()
    
    def test_remove_same_document_twice(self, engine):
        """æµ‹è¯•åˆ é™¤ç›¸åŒæ–‡æ¡£ä¸¤æ¬¡"""
        engine.add_document(1, {"content": "test content"})
        engine.flush()
        
        engine.remove_document(1)
        engine.remove_document(1)  # ç¬¬äºŒæ¬¡åˆ é™¤ä¸åº”è¯¥æŠ¥é”™
        engine.flush()
        
        result = engine.search("test")
        assert 1 not in result.to_list()
    
    def test_update_same_document_multiple_times(self, engine):
        """æµ‹è¯•å¤šæ¬¡æ›´æ–°åŒä¸€æ–‡æ¡£"""
        engine.add_document(1, {"content": "version 1"})
        engine.flush()
        
        engine.update_document(1, {"content": "version 2"})
        engine.update_document(1, {"content": "version 3"})
        engine.flush()
        
        # åªæœ‰æœ€æ–°ç‰ˆæœ¬åº”è¯¥è¢«æœç´¢åˆ°
        result = engine.search("version")
        assert 1 in result.to_list()
    
    def test_add_after_remove(self, engine):
        """æµ‹è¯•åˆ é™¤åŽé‡æ–°æ·»åŠ """
        engine.add_document(1, {"content": "original content"})
        engine.flush()
        
        engine.remove_document(1)
        engine.flush()
        
        engine.add_document(1, {"content": "new content"})
        engine.flush()
        
        result = engine.search("original")
        assert 1 not in result.to_list()
        
        result = engine.search("new")
        assert 1 in result.to_list()


class TestQueryVariations:
    """æŸ¥è¯¢å˜ä½“æµ‹è¯•"""
    
    def test_case_insensitive_search(self, engine):
        """æµ‹è¯•å¤§å°å†™ä¸æ•æ„Ÿæœç´¢"""
        engine.add_document(1, {"content": "Hello World"})
        engine.flush()
        
        assert engine.search("hello").total_hits == engine.search("HELLO").total_hits
        assert engine.search("world").total_hits == engine.search("WORLD").total_hits
    
    def test_single_character_search(self, engine):
        """æµ‹è¯•å•å­—ç¬¦æœç´¢"""
        engine.add_document(1, {"content": "a b c d e"})
        engine.flush()
        
        # ç”±äºŽ min_term_length é»˜è®¤æ˜¯ 2ï¼Œå•å­—ç¬¦å¯èƒ½æœä¸åˆ°
        result = engine.search("a")
        # ä¸å´©æºƒå³å¯
    
    def test_chinese_single_character(self, engine):
        """æµ‹è¯•ä¸­æ–‡å•å­—ç¬¦æœç´¢"""
        engine.add_document(1, {"content": "ä¸­å›½åŒ—äº¬"})
        engine.flush()
        
        # ä¸­æ–‡åº”è¯¥æŒ‰ n-gram å¤„ç†
        result = engine.search("ä¸­å›½")
        assert 1 in result.to_list()
    
    def test_search_with_leading_trailing_spaces(self, engine):
        """æµ‹è¯•å¸¦å‰åŽç©ºæ ¼çš„æŸ¥è¯¢"""
        engine.add_document(1, {"content": "hello world"})
        engine.flush()
        
        result1 = engine.search("hello")
        result2 = engine.search("  hello  ")
        
        # åº”è¯¥å¾—åˆ°ç›¸åŒç»“æžœ
        assert result1.total_hits == result2.total_hits


class TestMemoryMode:
    """å†…å­˜æ¨¡å¼æµ‹è¯•"""
    
    def test_memory_mode_basic(self, memory_engine):
        """æµ‹è¯•å†…å­˜æ¨¡å¼åŸºæœ¬åŠŸèƒ½"""
        assert memory_engine.is_memory_only()
        
        memory_engine.add_document(1, {"content": "test content"})
        # å†…å­˜æ¨¡å¼ä¸‹ flush åº”è¯¥æ˜¯ no-op
        memory_engine.flush()
        
        result = memory_engine.search("test")
        assert 1 in result.to_list()
    
    def test_memory_mode_no_persistence(self, memory_engine):
        """æµ‹è¯•å†…å­˜æ¨¡å¼ä¸æŒä¹…åŒ–"""
        memory_engine.add_document(1, {"content": "test content"})
        
        # å³ä½¿ä¸ flush ä¹Ÿèƒ½æœç´¢åˆ°
        result = memory_engine.search("test")
        assert 1 in result.to_list()


class TestConfigOptions:
    """é…ç½®é€‰é¡¹æµ‹è¯•"""
    
    def test_custom_chinese_length(self, tmp_index_file):
        """æµ‹è¯•è‡ªå®šä¹‰ä¸­æ–‡ n-gram é•¿åº¦"""
        engine = create_engine(
            tmp_index_file,
            max_chinese_length=2,
            drop_if_exists=True
        )
        
        engine.add_document(1, {"content": "ä¸­åŽäººæ°‘å…±å’Œå›½"})
        engine.flush()
        
        # åªèƒ½æœç´¢åˆ° 2-gram
        result = engine.search("ä¸­åŽ")
        assert 1 in result.to_list()
    
    def test_custom_min_term_length(self, tmp_index_file):
        """æµ‹è¯•è‡ªå®šä¹‰æœ€å°è¯æ¡é•¿åº¦"""
        engine = create_engine(
            tmp_index_file,
            min_term_length=3,
            drop_if_exists=True
        )
        
        engine.add_document(1, {"content": "ab abc abcd"})
        engine.flush()
        
        # åªæœ‰é•¿åº¦ >= 3 çš„è¯èƒ½è¢«ç´¢å¼•
        result = engine.search("abc")
        assert 1 in result.to_list()
        
        result = engine.search("ab")
        assert 1 not in result.to_list()
    
    def test_fuzzy_config(self, tmp_index_file):
        """æµ‹è¯•æ¨¡ç³Šæœç´¢é…ç½®"""
        engine = create_engine(
            tmp_index_file,
            fuzzy_threshold=0.5,
            fuzzy_max_distance=3,
            drop_if_exists=True
        )
        
        engine.add_document(1, {"content": "hello world"})
        engine.flush()
        
        # æµ‹è¯•æ¨¡ç³Šæœç´¢
        result = engine.fuzzy_search("helo", min_results=0)  # æ‹¼å†™é”™è¯¯
        # ä¸»è¦ç¡®ä¿ä¸å´©æºƒ


class TestBoundaryConditions:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""
    
    def test_flush_empty_buffer(self, engine):
        """æµ‹è¯•ç©ºç¼“å†²åŒº flush"""
        # ä¸æ·»åŠ ä»»ä½•æ•°æ®ï¼Œç›´æŽ¥ flush
        result = engine.flush()
        assert result == 0
    
    def test_multiple_flushes(self, engine):
        """æµ‹è¯•å¤šæ¬¡ flush"""
        engine.add_document(1, {"content": "test"})
        engine.flush()
        engine.flush()  # ç¬¬äºŒæ¬¡ flush åº”è¯¥æ˜¯ no-op
        engine.flush()  # ç¬¬ä¸‰æ¬¡ flush
        
        result = engine.search("test")
        assert 1 in result.to_list()
    
    def test_search_immediately_after_add(self, engine):
        """æµ‹è¯•æ·»åŠ åŽç«‹å³æœç´¢ï¼ˆä¸ flushï¼‰"""
        engine.add_document(1, {"content": "immediate test"})
        
        # ä¸ flush ä¹Ÿåº”è¯¥èƒ½æœç´¢åˆ°ï¼ˆä»Ž buffer ä¸­ï¼‰
        result = engine.search("immediate")
        assert 1 in result.to_list()
    
    def test_compact_empty_index(self, engine):
        """æµ‹è¯•å¯¹ç©ºç´¢å¼•è¿›è¡Œ compact"""
        engine.compact()  # ä¸åº”è¯¥å´©æºƒ
    
    def test_compact_after_flush(self, engine):
        """æµ‹è¯• flush åŽ compact"""
        engine.add_document(1, {"content": "test content"})
        engine.flush()
        engine.compact()
        
        result = engine.search("test")
        assert 1 in result.to_list()
    
    def test_stats_on_empty_engine(self, engine):
        """æµ‹è¯•ç©ºå¼•æ“Žçš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = engine.stats()
        
        assert stats["search_count"] == 0
        assert stats["term_count"] == 0
    
    def test_term_count_consistency(self, engine):
        """æµ‹è¯•è¯æ¡è®¡æ•°ä¸€è‡´æ€§"""
        initial_count = engine.term_count()
        
        engine.add_document(1, {"content": "hello world"})
        after_add_count = engine.term_count()
        
        assert after_add_count >= initial_count


if __name__ == "__main__":
    pytest.main([__file__, "-v"])


